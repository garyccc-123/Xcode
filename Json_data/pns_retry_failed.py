import json
import time
from datetime import datetime
import concurrent.futures
import hashlib  # For UID generation

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

CHROMEDRIVER_PATH = "/opt/homebrew/bin/chromedriver"  # Adjust this path as needed

def init_driver():
    """åˆå§‹åŒ– Chrome ç€è¦½å™¨ (éœ€èˆ‡ä¸»çˆ¬èŸ²çš„åšæ³•ä¸€è‡´)"""
    service = Service(CHROMEDRIVER_PATH)
    options = webdriver.ChromeOptions()
    # options.add_argument("--headless")  # å¦‚éœ€ç„¡é ­æ¨¡å¼å¯å–æ¶ˆè¨»è§£
    return webdriver.Chrome(service=service, options=options)

def fetch_product_details(url):
    """
    èˆ‡ä¸»ç¨‹å¼ç›¸åŒ: é€²å…¥å•†å“é é¢å¾Œï¼ŒæŠ“å– (name, price, offer, date, image_url)ã€‚
    è‹¥ç¼ºå¤± name æˆ– price å°±è¿”å› Noneã€‚
    æ–°å¢éƒ¨åˆ†ï¼šé€éé»æ“Šè‹±æ–‡æŒ‰éˆ•åˆ‡æ›è‡³è‹±æ–‡é é¢æŠ“å–è‹±æ–‡å•†å“åç¨±ï¼Œ
    çµæ§‹ä¸­æ–°å¢ product_eng_name æ¬„ä½ã€‚
    """
    print(f"ğŸ”µ [RETRY] é–‹å§‹æ“·å–å•†å“è³‡è¨Š: {url}")
    capture_date = datetime.now().strftime("%d/%m/%Y")
    product_data = {
        "url": url,
        "name": None,
        "price": None,
        "offer": "(ç„¡ç‰¹åˆ¥ä¿ƒéŠ·)",
        "date": capture_date,
        "image_url": None,
        "product_eng_name": "(å°šæœªå–å¾—è‹±æ–‡åç¨±)"
    }
    driver = init_driver()
    try:
        driver.get(url)
        wait = WebDriverWait(driver, 15)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.productName")))
        # å•†å“åç¨± + å–®ä½
        try:
            name_elem = driver.find_element(By.CSS_SELECTOR, "div.productName")
            product_data["name"] = name_elem.text.strip()
            try:
                unit_elem = driver.find_element(By.CSS_SELECTOR, "div.productUnit")
                product_unit = unit_elem.text.strip()
                product_data["name"] += f" {product_unit}"
            except Exception:
                pass
        except Exception as e:
            print(f"âš ï¸ [RETRY] ç„¡æ³•ç²å–å•†å“åç¨±æˆ–å–®ä½: {e}")
        # åƒ¹æ ¼
        try:
            price_elem = driver.find_element(By.CSS_SELECTOR, "span.currentPrice")
            product_data["price"] = price_elem.text.strip()
        except Exception as e:
            print(f"âš ï¸ [RETRY] ç„¡æ³•ç²å–åƒ¹æ ¼: {e}")
        # å¤šä»¶å„ªæƒ 
        try:
            multi_buy_elem = driver.find_element(By.CSS_SELECTOR, "div.multi-buy-count")
            product_data["offer"] = multi_buy_elem.text.strip()
        except Exception as e:
            print(f"âš ï¸ [RETRY] ç„¡æ³•ç²å–å¤šä»¶å„ªæƒ : {e}")
        # å…è²»è´ˆå“
        try:
            free_gift_elem = driver.find_element(By.CSS_SELECTOR, "div.free-gift-title")
            free_gift_text = free_gift_elem.text.strip()
            if product_data["offer"] != "(ç„¡ç‰¹åˆ¥ä¿ƒéŠ·)":
                product_data["offer"] += f" + è´ˆå“ï¼š{free_gift_text}"
            else:
                product_data["offer"] = f"è´ˆå“ï¼š{free_gift_text}"
        except Exception as e:
            print(f"âš ï¸ [RETRY] ç„¡æ³•ç²å–å…è²»è´ˆå“: {e}")
        # ä¸»åœ–
        try:
            large_img_elem = driver.find_element(
                By.CSS_SELECTOR, 
                "swiper.largePhoto .swiper-slide-active img"
            )
            product_data["image_url"] = large_img_elem.get_attribute("src")
        except Exception as e:
            print(f"âš ï¸ [RETRY] ç„¡æ³•ç²å–ä¸»åœ–: {e}")
    except Exception as e:
        print(f"âŒ [RETRY] æŠ“å–å•†å“è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        # å¦‚æœå¿…é ˆæ¬„ä½ç¼ºå¤±å‰‡æå‰é€€å‡º
        if not product_data["name"] or not product_data["price"]:
            driver.quit()
            return None

        # -------------------------------
        # æ–°å¢éƒ¨åˆ†ï¼šé»æ“Šè‹±æ–‡æŒ‰éˆ•åˆ‡æ›è‡³è‹±æ–‡é é¢ä¸¦å–å¾—è‹±æ–‡å•†å“åç¨±
        print(f"[INFO] æº–å‚™åˆ‡æ›è‡³è‹±æ–‡é é¢ï¼š{url}")
        try:
            print("[INFO] å˜—è©¦å°‹æ‰¾è‹±æ–‡åˆ‡æ›é€£çµ (åƒ…ä¾æ“š href)...")
            # ä½¿ç”¨ XPath æ ¹æ“š href åŒ…å« '/en/' çš„é€£çµ
            eng_button = driver.find_element(By.XPATH, "//a[contains(@href, '/en/')]")
            print("[INFO] æ‰¾åˆ°è‹±æ–‡åˆ‡æ›é€£çµï¼Œé»æ“Šåˆ‡æ›...")
            eng_button.click()
            # ç­‰å¾…è‹±æ–‡é é¢è¼‰å…¥ï¼ˆå‡è¨­è‹±æ–‡é é¢ä»ä½¿ç”¨ div.productName é¡¯ç¤ºå•†å“åç¨±ï¼‰
            wait = WebDriverWait(driver, 25)
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.productName")))
            eng_name_elem = driver.find_element(By.CSS_SELECTOR, "div.productName")
            eng_name = eng_name_elem.text.strip()
            if eng_name:
                print(f"[INFO] è‹±æ–‡å•†å“åç¨±å–å¾—: {eng_name}")
            else:
                print("[WARN] è‹±æ–‡å•†å“åç¨±ç‚ºç©º")
            product_data["product_eng_name"] = eng_name
        except Exception as e:
            print(f"[DEBUG] åˆ‡æ›è‹±æ–‡é é¢å¤±æ•—: {url}, éŒ¯èª¤: {e}")
            product_data["product_eng_name"] = "(ç„¡æ³•æ“·å–è‹±æ–‡åç¨±)"
        driver.quit()

    if not product_data["name"] or not product_data["price"]:
        return None
    return product_data

def main():
    # 1) è®€å– fail_products.json
    try:
        with open("fail_products.json", "r", encoding="utf-8") as f:
            fail_list = json.load(f)
    except Exception as e:
        print(f"âŒ ç„¡æ³•è®€å– fail_products.jsonï¼Œè«‹å…ˆç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢ºã€‚éŒ¯èª¤: {e}")
        return

    if not fail_list:
        print("âœ… æ²’æœ‰ä»»ä½•å¤±æ•—é€£çµéœ€è¦é‡è©¦ã€‚")
        return

    print(f"ğŸ” æº–å‚™é‡è©¦ {len(fail_list)} ç­†å¤±æ•—é€£çµ...")

    # 2) è®€å– combined_products_pns.json
    try:
        with open("combined_products_pns.json", "r", encoding="utf-8") as f:
            combined_data = json.load(f)
    except Exception as e:
        print(f"âŒ ç„¡æ³•è®€å– combined_products_pns.jsonï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢ºã€‚éŒ¯èª¤: {e}")
        return

    products_list = combined_data.get("products", [])
    # è½‰æˆ dict æ–¹ä¾¿æ›´æ–° (key: url)
    product_dict = {}
    for item in products_list:
        url = item["url"]
        product_dict[url] = item
        # å¦‚æœæ²’æœ‰ uidï¼Œå‰‡åŠ å…¥ uid
        if "uid" not in product_dict[url]:
            product_dict[url]["uid"] = hashlib.md5(url.encode("utf-8")).hexdigest()

    # 3) ç”¨å¤šåŸ·è¡Œç·’é‡è©¦
    still_fail = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_item = {
            executor.submit(fetch_product_details, item["url"]): item 
            for item in fail_list
        }
        for future in concurrent.futures.as_completed(future_to_item):
            fail_item = future_to_item[future]
            url = fail_item["url"]
            data = future.result()
            if data:
                print(f"âœ… [RETRY] æˆåŠŸæ“·å–: {url}")
                new_record = {
                    "name": data["name"],
                    "price": data["price"],
                    "offer": data["offer"],
                    "date": data["date"],
                    "image_url": data["image_url"],
                    "product_eng_name": data["product_eng_name"]
                }
                # å¦‚æœè©² URL ä¸åœ¨ product_dict ä¸­ï¼Œå‰‡æ–°å»º
                if url not in product_dict:
                    product_dict[url] = {
                        "url": url,
                        "main_category": fail_item.get("main_category", []),
                        "sub_categories": fail_item.get("sub_categories", []),
                        "history": [],
                        "uid": hashlib.md5(url.encode("utf-8")).hexdigest()  # ç”Ÿæˆ uid
                    }
                # åˆä½µ main_category èˆ‡ sub_categories
                for cat in fail_item.get("main_category", []):
                    if "main_category" in product_dict[url] and cat not in product_dict[url]["main_category"]:
                        product_dict[url]["main_category"].append(cat)
                for subcat in fail_item.get("sub_categories", []):
                    if "sub_categories" in product_dict[url] and subcat not in product_dict[url]["sub_categories"]:
                        product_dict[url]["sub_categories"].append(subcat)
                # åŠ å…¥æ–°çš„ history ç´€éŒ„
                product_dict[url]["history"].append(new_record)
                # æ›´æ–°æœ€æ–°æ¬„ä½
                product_dict[url]["name"] = data["name"]
                product_dict[url]["price"] = data["price"]
                product_dict[url]["offer"] = data["offer"]
                product_dict[url]["date"] = data["date"]
                product_dict[url]["image_url"] = data["image_url"]
                product_dict[url]["product_eng_name"] = data["product_eng_name"]
            else:
                print(f"âŒ [RETRY] ä»ç„¶å¤±æ•—: {url}")
                still_fail.append(fail_item)

    # 4) æ›´æ–° combined_data çš„ products èˆ‡ update_date
    updated_products = list(product_dict.values())
    combined_data["products"] = updated_products
    combined_data["update_date"] = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

    # 5) å¯«å› combined_products_pns_with_eng.json
    try:
        with open("combined_products_pns_with_eng.json", "w", encoding="utf-8") as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"âŒ å¯«å…¥ combined_products_pns_with_eng.json å¤±æ•—: {e}")

    # 6) å¯«å›æ–°çš„ fail_products.json (ä»å¤±æ•—çš„å•†å“)
    try:
        with open("fail_products.json", "w", encoding="utf-8") as f:
            json.dump(still_fail, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"âŒ å¯«å…¥ fail_products.json å¤±æ•—: {e}")

    print(f"\nâœ… é‡è©¦çµæŸï¼ŒæˆåŠŸä¿®å¾© {len(fail_list) - len(still_fail)} ç­†ï¼Œä»å¤±æ•— {len(still_fail)} ç­†ã€‚")

if __name__ == "__main__":
    main()