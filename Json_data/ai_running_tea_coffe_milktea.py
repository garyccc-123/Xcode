#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ai_running_milk_yogurt.py

1. å¾ normalized_soda_updated.json å–ç¤ºç¯„ï¼Œæä¾›çµ¦ LLM ç•¶æ ¼å¼ç¯„ä¾‹ã€‚
2. å° filtered_tea_coffe_milktea.json ä¾ã€Œå“ç‰Œ â†’ ç³»åˆ—/å£å‘³ â†’ å®¹é‡ã€ä¸‰å±¤èšé¡ã€‚
3. èšé¡çµæœç›´æ¥å¯«å› rec["norm"]ï¼Œä¸¦è¼¸å‡º normalized_tea_coffe_milktea.jsonï¼Œ
   ä¾ norm å‡åºæ’åºæ–¹ä¾¿æª¢æŸ¥ï¼ˆçµ‚ç«¯ä¹Ÿåƒ…åˆ—å°å”¯ä¸€ normï¼‰ã€‚
"""

import os
import json
import re
from collections import OrderedDict
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


# ------------------ å·¥å…· ----------------------------------------------------

CAP_RE = re.compile(r"(\d+(?:\.\d+)?)\s*(?:ml|mL|ML|l|L|g|G)")

def _dedupe_keep_order(seq):
    seen = set()
    for x in seq:
        if x not in seen:
            seen.add(x)
            yield x

def _clean_capacity(text: str) -> str:
    m = CAP_RE.search(text)
    if not m:
        return ""
    num = m.group(1)
    unit = "ml" if "l" not in m.group(0).lower() else "l"
    if unit == "l":
        num = str(int(float(num) * 1000))          # 1.5L â†’ 1500ml
    return f"{num}ml"

def _clean_canonical(raw: str) -> str:
    parts = [p.strip() for p in raw.strip().split("â†’") if p.strip()]
    cleaned = " â†’ ".join(_dedupe_keep_order(parts))
    if cleaned:
        pcs = cleaned.split(" â†’ ")
        cap = _clean_capacity(pcs[-1])
        if cap:
            pcs[-1] = cap
        cleaned = " â†’ ".join(pcs)
    return cleaned.lower()


# ------------------ ä¸»æµç¨‹ ---------------------------------------------------

def main() -> None:
    base = os.path.dirname(os.path.abspath(__file__))

    # 1) è®€ç¤ºç¯„ï¼ˆsodaï¼‰
    demo_path = os.path.join(base, "normalized_soda_updated.json")
    with open(demo_path, encoding="utf-8") as f:
        soda = json.load(f)

    demo_clusters = OrderedDict()
    for rec in soda:
        demo_clusters.setdefault(rec["norm"], []).append(rec["norm"])

    example_blocks = [
        json.dumps({"canonical": canon, "members": sorted(set(mems))},
                   ensure_ascii=False, indent=2)
        for canon, mems in list(demo_clusters.items())[:10]   # ç¯„ä¾‹æŠ“å‰ 10 ç¾¤
    ]
    demo_examples = "\n\n".join(example_blocks)

    # 2) è®€å¾…è™•ç†æª”
    src = os.path.join(base, "filtered_tea_coffe_milktea.json")
    with open(src, encoding="utf-8") as f:
        data = json.load(f)
    if not data:
        raise ValueError("filtered_tea_coffe_milktea.json ç‚ºç©ºï¼")

    field = "norm" if "norm" in data[0] else "eng"
    names = list(_dedupe_keep_order(item.get(field, "") for item in data))
    print(f"âš™ï¸ ä½¿ç”¨æ¬„ä½ã€Œ{field}ã€èšé¡ï¼›æ¨£æœ¬ {len(names)} ç­†")

   # 3) LLM prompt ----------------------------------------------------------
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªèšç±»åŠ©æ‰‹ï¼Œåªè¿”å›çº¯ JSONï¼Œä¸è¦è¾“å‡ºä»»ä½•å¤šä½™æ–‡å­—ã€‚\n"
        "è¯·æŒ‰ç…§ä»¥ä¸‹ä¼˜å…ˆçº§ï¼Œå¯¹ã€å³é¥®èŒ¶ï¼å’–å•¡ï¼å¥¶èŒ¶ã€‘äº§å“è¿›è¡Œåˆ†å±‚èšç±»ï¼š\n"
        "1. å“ç‰Œï¼ˆå¦‚ asahiã€nescafeã€vitaï¼‰\n"
        "2. äº§å“ç³»åˆ—æˆ–å£å‘³ï¼ˆå¦‚ wondaã€cold brewã€lemon teaã€æ— ç³–ï¼‰\n"
        "3. å®¹é‡ï¼ˆç»Ÿä¸€å†™æˆæ•°å­—+mlï¼Œä¾‹å¦‚ 330mlã€500mlã€1500mlï¼‰\n"
        "ä¸ºæ¯ä¸ªç°‡æŒ‡å®šä¸€ä¸ªâ€œè§„èŒƒåç§°â€ï¼ˆcanonicalï¼‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
        "{\n"
        "  \"1\": {\"canonical\": \"å“ç‰Œ â†’ ç³»åˆ—/å£å‘³ â†’ å®¹é‡\", \"members\": [\"â€¦\", \"â€¦\"]},\n"
        "  â€¦\n"
        "}\n"
        "è§„åˆ™ï¼š\n"
        "â€¢ canonical ä¸ members å…¨éƒ¨ç”¨å°å†™ï¼Œå»æ‰å¤šä½™ç©ºæ ¼ã€æ‹¬å·ä¸åŒ…è£…è¯´æ˜ã€‚\n"
        "â€¢ è‹¥æ— æ³•åˆ¤å®šå“ç‰Œï¼Œç”¨ \"unknown\" ä»£æ›¿ã€‚\n"
        "â€¢ ä»…è¿”å› JSONï¼Œä¸åŒ…å«ä»»ä½•æ€è€ƒæˆ–è¯´æ˜ã€‚\n"
        "â€¢ åœ¨æ€è€ƒéƒ¨åˆ†å’Œ JSON éƒ¨åˆ†ä¹‹é—´ï¼Œç”¨ä¸€è¡Œ â€œ----JSON----â€ åˆ†éš”ã€‚\n"
        "â€¢ æ€»ç°‡æ•°ä¸å¾—è¶…è¿‡ âŒˆæ ·æœ¬æ•° Ã· 8âŒ‰ã€‚\n"
    )
    # -----------------------------------------------------------------------

    api_url = "http://192.168.50.98:1234/v1/chat/completions"
    payload = {
        "model": "llama3.2",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ç”¢å“æ¸…å–®å¦‚ä¸‹ï¼š\n" + "\n".join(names)}
        ],
        "temperature": 0.0,
        "max_tokens": 12508
    }

    sess = requests.Session()
    sess.mount("http://", HTTPAdapter(
        max_retries=Retry(total=3, backoff_factor=1,
                          status_forcelist=[502, 503, 504],
                          allowed_methods=["POST"])
    ))

    try:
        res = sess.post(api_url, json=payload)
        res.raise_for_status()
    except Exception as exc:
        raise RuntimeError(f"ğŸš¨ å‘¼å«æœ¬åœ° LLM å¤±æ•—ï¼š{exc}")

    content = res.json()["choices"][0]["message"]["content"]
    json_part = content.split("----JSON----", 1)[-1].strip()

    # æ“·å–æœ€å¤–å±¤ JSON
    depth = 0; s = e = None
    for i, ch in enumerate(json_part):
        if ch == "{":
            if depth == 0:
                s = i
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                e = i
                break
    if s is None or e is None:
        raise ValueError("âš ï¸ ç„¡æ³•å®šä½ JSON å€å¡Š")
    clusters = json.loads(json_part[s:e+1])

    # 4) æ¸…æ´— canonicalï¼ˆç›¸å®¹å…©ç¨®æ ¼å¼ï¼‰ ----------------------------- ###
    cleaned = OrderedDict()
    for outer_key, info in clusters.items():

        # â–¶ â‘  è‹¥ value ç‚º dict ä¸”å« canonical
        if isinstance(info, dict) and "canonical" in info:
            canon_raw = info["canonical"]
            members_raw = info.get("members", [])
        # â–¶ â‘¡ å¦å‰‡æŠŠå¤–å±¤ key ç•¶ canonicalï¼Œvalue æ‡‰ç‚º members list
        else:
            canon_raw = outer_key
            members_raw = info if isinstance(info, list) else []

        canon = _clean_canonical(canon_raw)
        members = sorted({m.lower() for m in members_raw})
        cleaned[canon] = {"canonical": canon, "members": members}
    # -------------------------------------------------------------- ###

    # 5) å»ºå°ç…§ & å›å¯« norm
    name2canon = {}
    for info in cleaned.values():
        for m in info["members"]:
            key = re.sub(r"\s*\([^)]*\)", "", m).strip()
            name2canon[key] = info["canonical"]

    normalized = []
    for rec in data:
        raw = rec.get(field, "")
        key = re.sub(r"\s*\([^)]*\)", "", raw.lower()).strip()
        rec["norm"] = name2canon.get(key, key)       # ç›´æ¥è¦†å¯« norm
        normalized.append(rec)

    normalized.sort(key=lambda x: x["norm"])

    print("\nğŸ” å”¯ä¸€ normï¼ˆä¾›äººå·¥æª¢æŸ¥ï¼‰:")
    for n in OrderedDict.fromkeys(r["norm"] for r in normalized):
        print(" -", n)

    out = os.path.join(base, "normalized_tea_coffe_milktea.json")
    with open(out, "w", encoding="utf-8") as f:
        json.dump(normalized, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å®Œæˆï¼{len(normalized)} ç­†å¯«å…¥ {out}")


if __name__ == "__main__":
    main()