#!/usr/bin/env python3
# ai_running_soda.py

import os
import json
import re
import requests

def main():
    # 1ï¸âƒ£ å®šä½ JSON æ–‡ä»¶
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    filtered_path = os.path.join(BASE_DIR, 'filtered_soda.json')
    with open(filtered_path, encoding='utf-8') as f:
        data = json.load(f)
    if not data:
        raise ValueError("filtered_soda.json ä¸ºç©ºï¼")

    # 2ï¸âƒ£ é€‰ç”¨èšç±»å­—æ®µï¼šä¼˜å…ˆä½¿ç”¨ normï¼Œå¦åˆ™ä½¿ç”¨ eng
    field = 'norm' if 'norm' in data[0] else 'eng'
    print(f"âš™ï¸ ä½¿ç”¨å­—æ®µâ€œ{field}â€è¿›è¡Œæ±½æ°´èšç±»ã€‚")

    # 3ï¸âƒ£ æ„é€  Prompt åˆ—è¡¨
    names = sorted({item.get(field, '') for item in data})
    soda_list = "\n".join(names)

    # 4ï¸âƒ£ å‘é€è¯·æ±‚åˆ°æœ¬åœ° LM Studioï¼ˆDeepseekï¼‰
    API_URL = "http://192.168.50.98:1234/v1/chat/completions"  # æ›¿æ¢ä¸ºä½ çš„ IP:ç«¯å£
    payload = {
        "model": "llama3.2",
        "messages": [
            {"role": "system", "content": (
                "ä½ æ˜¯ä¸€ä¸ªèšç±»åŠ©æ‰‹ï¼Œåªè¿”å›çº¯ JSONï¼Œä¸è¦è¾“å‡ºä»»ä½•å¤šä½™æ–‡å­—ã€‚\n"
                "åœ¨åˆ†ç»„æ—¶è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š\n"
                "1. æŒ‰è¯­ä¹‰æˆ–æ‹¼å†™ç›¸ä¼¼åº¦åˆ†ç°‡ï¼›\n"
                "2. ä¸ºæ¯ä¸ªç°‡æŒ‡å®šä¸€ä¸ªâ€˜è§„èŒƒåç§°â€™ï¼›\n"
                "**è¯·ä»…è¿”å›çº¯ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™è¯´æ˜ã€‚**\n"
                "JSON æ ¼å¼ï¼š{\n"
                "  \"1\": {\"canonical\": \"â€¦\", \"members\": [â€¦]},\n"
                "  â€¦\n"
                "}\n"
                "è¯·åœ¨æ€è€ƒéƒ¨åˆ†å’Œ JSON éƒ¨åˆ†ä¹‹é—´ï¼Œç”¨ä¸€è¡Œ â€œ----JSON----â€ åˆ†éš”ã€‚"
            )},
            {"role": "user", "content": (
                "ä¸‹é¢æ˜¯ä¸€ç»„æ±½æ°´åç§°åˆ—è¡¨ï¼Œè¯·å¸®æˆ‘ï¼š\n"
                "1. æŒ‰è¯­ä¹‰æˆ–æ‹¼å†™ç›¸ä¼¼åº¦åˆ†ç°‡ï¼›\n"
                "2. ä¸ºæ¯ä¸ªç°‡æŒ‡å®šä¸€ä¸ªâ€˜è§„èŒƒåç§°â€™ï¼›\n"
                "**è¯·ä»…è¿”å›çº¯ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™è¯´æ˜ã€‚**\n"
                "æ±½æ°´åˆ—è¡¨ï¼š\n" + soda_list
            )}
        ],
        "temperature": 0.0,
        "max_tokens": 12508
    }
    response = requests.post(API_URL, json=payload)
    response.raise_for_status()

    # 5ï¸âƒ£ æ‹†åˆ†æ€è€ƒä¸ JSON
    content = response.json()["choices"][0]["message"]["content"]
    parts = content.split("----JSON----", 1)
    think_part, json_part = (parts + ["", ""])[:2]

    # å†™å…¥æ€è€ƒåˆ° debug.txt
    debug_path = os.path.join(BASE_DIR, "debug.txt")
    with open(debug_path, "w", encoding="utf-8") as dbg:
        dbg.write(think_part.strip())
    print(f"ğŸ“ å·²å°†æ¨¡å‹æ€è€ƒå†™å…¥ï¼š{debug_path}")

    # 5.1ï¸âƒ£ ç”¨æ·±åº¦è®¡æ•°æˆªå–æœ€å¤–å±‚ JSON
    text = json_part.strip()
    depth = 0
    start_idx = None
    end_idx = None
    for i, ch in enumerate(text):
        if ch == '{':
            depth += 1
            if start_idx is None:
                start_idx = i
        elif ch == '}':
            depth -= 1
            if depth == 0:
                end_idx = i
                break
    if start_idx is None or end_idx is None:
        print("----JSON PART----")
        print(json_part)
        raise ValueError("æ— æ³•å®šä½æœ€å¤–å±‚ JSON çš„èµ·æ­¢ä½ç½®ã€‚")
    json_text = text[start_idx:end_idx+1]

    # 5.2ï¸âƒ£ è§£æ JSON éƒ¨åˆ†
    try:
        clusters = json.loads(json_text)
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON è§£æå¤±è´¥ï¼š{e}\nJSON å†…å®¹ï¼š\n{json_text}")

    # 6ï¸âƒ£ æ„å»º name->canonical çš„æ˜ å°„
    name2canon = {
        nm: info.get("canonical", nm)
        for info in clusters.values()
        for nm in info.get("members", [])
    }

    normalized = []
    seen_canons = set()
    for item in data:
        raw = item.get(field, "")
        # 1ï¸âƒ£ å½’ä¸€åŒ–ä¸ºå°å†™å¹¶å»æ‰æ‹¬å·åŠå…¶å†…å®¹
        norm = raw.lower()
        norm = re.sub(r'\s*\([^)]*\)', '', norm).strip()

        # 2ï¸âƒ£ å¯¹ Coca-Cola Zero / No Sugar åšç‰¹æ®Šå¤„ç†
        if re.search(r"coca[- ]cola.*zero", norm) or re.search(r"coca[- ]cola.*no sugar", norm):
            canon = "coca cola zero"
        else:
            # 3ï¸âƒ£ å¦åˆ™ç”¨èšç±»ç»“æœ
            canon = name2canon.get(norm, norm)

        item['canonical_name'] = canon
        normalized.append(item)
        seen_canons.add(canon)

    # æ‰“å°æ‰€æœ‰ unique canonical_nameï¼Œä¾¿äºå¤æ ¸
    print("ğŸ” æ‰€æœ‰ unique canonical_name å€¼ï¼š")
    for c in sorted(seen_canons):
        print(f"- {c}")

    # 7ï¸âƒ£ è¾“å‡º normalized_soda.json
    output_path = os.path.join(BASE_DIR, 'normalized_soda.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(normalized, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ç”Ÿæˆ {output_path}ï¼Œå…± {len(normalized)} æ¡è®°å½•ã€‚")

if __name__ == "__main__":
    main()
